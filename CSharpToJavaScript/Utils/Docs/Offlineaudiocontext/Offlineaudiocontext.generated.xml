<docs>
<OfflineAudioContext>
<summary>
The <c>OfflineAudioContext</c> interface is an <see cref="AudioContext"/> interface representing an audio-processing graph built from linked together <see cref="AudioNode"/>s. In contrast with a standard <see cref="AudioContext"/>, an <c>OfflineAudioContext</c> doesn't render the audio to the device hardware; instead, it generates it, as fast as it can, and outputs the result to an <see cref="AudioBuffer"/>.
</summary>
<remarks>
<para></para>
<para>-<see href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</see><br/></para>
<para><seealso href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext"> <em>See also on MDN</em> </seealso></para>
</remarks>
</OfflineAudioContext>
<OfflineAudioContextComplete>
<summary>
The <c>complete</c> event of the <see cref="OfflineAudioContext"/> interface is fired when the rendering of an offline audio context is complete.
</summary>
<remarks>
<para>This event is not cancelable and does not bubble.</para>
<para>-<see href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">Web Audio API</see><br/></para>
<para><seealso href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext/complete"> <em>See also on MDN</em> </seealso></para>
</remarks>
</OfflineAudioContextComplete>
<OfflineAudioContextLength>
<summary>
The <strong><c>length</c></strong> property of the<br/><see cref="OfflineAudioContext"/> interface returns an integer representing the size of<br/>the buffer in sample-frames.
</summary>
<remarks>
<para><seealso href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext/length"> <em>See also on MDN</em> </seealso></para>
</remarks>
<value>An integer representing the size of the buffer in sample-frames.</value>
</OfflineAudioContextLength>
<OfflineAudioContextOfflineAudioContext>
<summary>
The<br/><strong><c>OfflineAudioContext()</c></strong> constructor—part of the <see href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">Web Audio API</see>—creates and returns a new<br/><see cref="OfflineAudioContext"/> object instance, which can then be used to render<br/>audio to an <see cref="AudioBuffer"/> rather than to an audio output device.
</summary>
<remarks>
<para><seealso href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext/OfflineAudioContext"> <em>See also on MDN</em> </seealso></para>
</remarks>
<returns>A new <see cref="OfflineAudioContext"/> object whose associated<br/><c>AudioBuffer</c> is configured as requested.Like a regular <c>AudioContext</c>, an<br/><c>OfflineAudioContext</c> can be the target of events, therefore it implements<br/>the <see cref="EventTarget"/> interface.</returns>
</OfflineAudioContextOfflineAudioContext>
<OfflineAudioContextResume>
<summary>
The <strong><c>resume()</c></strong> method of the<br/><see cref="OfflineAudioContext"/> interface resumes the progression of time in an audio<br/>context that has been suspended. The promise resolves immediately because the<br/><c>OfflineAudioContext</c> does not require the audio hardware.
</summary>
<remarks>
<para><seealso href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext/resume"> <em>See also on MDN</em> </seealso></para>
</remarks>
<returns>A <see cref="Promise"/> resolving to <see cref="'undefined'"/>.</returns>
</OfflineAudioContextResume>
<OfflineAudioContextStartRendering>
<summary>
The <c>startRendering()</c> method of the <see cref="OfflineAudioContext"/> Interface starts rendering the audio graph, taking into account the current connections and the current scheduled changes.
</summary>
<remarks>
<para>The <see cref="OfflineAudioContextcomplete"/> event (of type <see cref="OfflineAudioCompletionEvent"/>) is raised when the rendering is finished, containing the resulting <see cref="AudioBuffer"/> in its <c>renderedBuffer</c> property.</para><para>Browsers currently support two versions of the <c>startRendering()</c> method — an older event-based version and a newer promise-based version.<br/>The former will eventually be removed, but currently both mechanisms are provided for legacy reasons.</para>
<para>-<see href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</see><br/></para>
<para><seealso href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext/startRendering"> <em>See also on MDN</em> </seealso></para>
</remarks>
<returns>A {{jsxref("Promise")}} that fulfills with an <see cref="AudioBuffer"/>.</returns>
</OfflineAudioContextStartRendering>
<OfflineAudioContextSuspend>
<summary>
The <strong><c>suspend()</c></strong> method of the <see cref="OfflineAudioContext"/> interface schedules a suspension of the time<br/>progression in the audio context at the specified time and returns a promise. This is<br/>generally useful at the time of manipulating the audio graph synchronously on<br/>OfflineAudioContext.
</summary>
<remarks>
<para>Note that the maximum precision of suspension is the size of the render quantum and the<br/>specified suspension time will be rounded down to the nearest render quantum boundary.<br/>For this reason, it is not allowed to schedule multiple suspends at the same quantized<br/>frame. Also scheduling should be done while the context is not running to ensure the<br/>precise suspension.</para>
<para><seealso href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext/suspend"> <em>See also on MDN</em> </seealso></para>
</remarks>
<returns>A <see cref="Promise"/> resolving to <see cref="'undefined'"/>.</returns>
</OfflineAudioContextSuspend>
</docs>